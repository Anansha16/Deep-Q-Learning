{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabiograetz/anaconda3/envs/deeplearning/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"dqn/animations/\"\n",
    "os.makedirs(PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-07-17 01:33:48,552] Making new env: BreakoutDeterministic-v3\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BreakoutDeterministic-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gif(sess, frame_number, frames_for_gif):\n",
    "    \n",
    "    for idx,frame_idx in enumerate(frames_for_gif): \n",
    "        frames_for_gif[idx] = resize(frame_idx,(420,320,3),preserve_range=True, order=0).astype(np.uint8)\n",
    "        \n",
    "    imageio.mimsave(f'{PATH}{\"pong_frame_{0}.gif\".format(frame_number)}', frames_for_gif, duration=1/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class processFrame():\n",
    "    def __init__(self):\n",
    "        self.frame = tf.placeholder(shape=[210, 160, 3], dtype=tf.uint8)\n",
    "        self.processed = tf.image.rgb_to_grayscale(self.frame)\n",
    "        self.processed = tf.image.crop_to_bounding_box(self.processed, 34, 0, 160, 160)\n",
    "        self.processed = tf.image.resize_images(self.processed, [84, 84], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    def process(self, sess, frame):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sess: A Tensorflow session object\n",
    "            frame: A (210, 160, 3) frame of an Atari game in RGB\n",
    "        Returns:\n",
    "            A processed (84, 84, 1) frame in grayscale\n",
    "        \"\"\"\n",
    "        return sess.run(self.processed, feed_dict={ self.frame:frame})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dqn():\n",
    "    def __init__(self, hidden=512, learning_rate=0.00005):\n",
    "        self.hidden = hidden\n",
    "        self.learning_rate = learning_rate\n",
    "        self.input = tf.placeholder(shape=[None,84,84,4], dtype=tf.float32)\n",
    "        self.inputscaled = self.input/255\n",
    "        self.conv1 = tf.layers.conv2d(\n",
    "            inputs=self.inputscaled, filters=32, kernel_size=[8,8], strides=4,\n",
    "            padding=\"valid\", activation=tf.nn.relu, use_bias=False)\n",
    "        self.conv2 = tf.layers.conv2d(\n",
    "            inputs=self.conv1, filters=64, kernel_size=[4,4], strides=2, \n",
    "            padding=\"valid\", activation=tf.nn.relu, use_bias=False)\n",
    "        self.conv3 = tf.layers.conv2d(\n",
    "            inputs=self.conv2, filters=64, kernel_size=[3,3], strides=1, \n",
    "            padding=\"valid\", activation=tf.nn.relu, use_bias=False)\n",
    "        self.conv4 = tf.layers.conv2d(\n",
    "            inputs=self.conv3, filters=hidden, kernel_size=[7,7], strides=1, \n",
    "            padding=\"valid\", activation=tf.nn.relu, use_bias=False)\n",
    "        self.valuestream, self.advantagestream = tf.split(self.conv4,2,3)\n",
    "        self.valuestream = tf.layers.flatten(self.valuestream)\n",
    "        self.advantagestream = tf.layers.flatten(self.advantagestream)\n",
    "        self.Advantage = tf.layers.dense(\n",
    "            inputs=self.advantagestream,units=env.action_space.n,\n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        self.Value = tf.layers.dense(\n",
    "            inputs=self.valuestream,units=1,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        self.Qvalues = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keepdims=True))\n",
    "        self.bestaction = tf.argmax(self.Qvalues,1)\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.action = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qvalues, tf.one_hot(self.action, env.action_space.n, dtype=tf.float32)), axis=1)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.losses.huber_loss(labels=self.targetQ, predictions=self.Q))\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate, 0.95, 0.0, 1e-6)\n",
    "        #self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)#0.0001\n",
    "        self.update = self.optimizer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getaction(frame_number,state, inference=False):\n",
    "    if frame_number < replay_start_size:\n",
    "        e = exploration_initial\n",
    "    if frame_number >= replay_start_size and frame_number < replay_start_size + exploration_decay_frames:\n",
    "        e = m*frame_number + b\n",
    "    if frame_number >= replay_start_size + exploration_decay_frames:\n",
    "        e = m2*frame_number + b2\n",
    "    if inference:\n",
    "        e = exploration_inference\n",
    "    if np.random.rand(1) < e:\n",
    "        return np.random.randint(0, env.action_space.n)\n",
    "    else:\n",
    "        return sess.run(mainDQN.bestaction, feed_dict={mainDQN.input:[state]})[0]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryBuffer:\n",
    "    def __init__(self, size = 1000000, frame_height=84, frame_width=84, agent_history_length = 4, batch_size = 32):\n",
    "        \n",
    "        self.size = size\n",
    "        self.frame_height = frame_height\n",
    "        self.frame_width = frame_width\n",
    "        self.agent_history_length = agent_history_length\n",
    "        self.batch_size = batch_size\n",
    "        self.count = 0\n",
    "        self.current = 0\n",
    "        \n",
    "        self.actions = np.empty(self.size, dtype=np.int32)\n",
    "        self.rewards = np.empty(self.size, dtype=np.float32)\n",
    "        self.frames = np.empty((self.size, self.frame_height,self.frame_width), dtype=np.uint8)\n",
    "        self.donestates = np.empty(self.size, dtype=np.bool)\n",
    "        \n",
    "        # Pre-allocate memory for the States and newStates in a minibatch\n",
    "        self.states = np.empty((self.batch_size, self.agent_history_length, self.frame_height, self.frame_width), dtype=np.uint8)\n",
    "        self.newstates = np.empty((self.batch_size, self.agent_history_length, self.frame_height, self.frame_width), dtype=np.uint8)\n",
    "        self.indices = np.empty(self.batch_size, dtype=np.int32)\n",
    "        \n",
    "    def addExperience(self, action, frame, reward, done):\n",
    "        \"\"\" \n",
    "        Adds an experience to the replay memory. Convention: array frames contains the newstates after the action\n",
    "        \"\"\"\n",
    "        if frame.shape != (self.frame_height, self.frame_width):\n",
    "            raise ValueError('Dimension of frame is wrong!')\n",
    "        self.actions[self.current] = action\n",
    "        self.frames[self.current,...] = frame\n",
    "        self.rewards[self.current] = reward\n",
    "        self.donestates[self.current] = done\n",
    "        \n",
    "        self.count = max(self.count, self.current+1)\n",
    "        self.current = (self.current + 1) % self.size\n",
    "        \n",
    "            \n",
    "    def getState(self, index):\n",
    "        if self.count is 0:\n",
    "            raise ValueError(\"The replay memory is empty!\")\n",
    "        if index < self.agent_history_length - 1:\n",
    "            raise ValueError(\"Index must be min 3\")\n",
    "        return self.frames[index-self.agent_history_length+1:index+1,...]\n",
    "        \n",
    "    def getValidIndices(self):\n",
    "        for i in range(self.batch_size):\n",
    "            while True:\n",
    "                index = random.randint(self.agent_history_length, self.count - 1)\n",
    "                if index < self.agent_history_length:\n",
    "                    continue\n",
    "                if index >= self.current and index - self.agent_history_length <= self.current:\n",
    "                    continue\n",
    "                if self.donestates[index - self.agent_history_length:index].any():\n",
    "                    continue\n",
    "                break\n",
    "            self.indices[i] = index\n",
    "            \n",
    "    def getMinibatch(self):\n",
    "        if self.count < self.agent_history_length:\n",
    "            raise ValueError('Not enough memories to get a minibatch')\n",
    "        self.getValidIndices()\n",
    "            \n",
    "        for i, idx in enumerate(self.indices):\n",
    "            self.states[i] = self.getState(idx - 1)\n",
    "            self.newstates[i] = self.getState(idx)\n",
    "        return np.transpose(self.states,axes=(0,2,3,1)), self.actions[self.indices], self.rewards[self.indices], np.transpose(self.newstates,axes=(0,2,3,1)), self.donestates[self.indices]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetVars_full(mainDQN_vars, targetDQN_vars):\n",
    "    update_ops = []\n",
    "    for i, var in enumerate(mainDQN_vars):\n",
    "        op = targetDQN_vars[i].assign(var.value())\n",
    "        update_ops.append(op)\n",
    "    return update_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn():\n",
    "    states, actions, rewards, newstates, dones = myMemoryBuffer.getMinibatch()    \n",
    "    argQmax = sess.run(mainDQN.bestaction, feed_dict={mainDQN.input:newstates})\n",
    "    Qvals = sess.run(targetDQN.Qvalues, feed_dict={targetDQN.input:newstates})\n",
    "    \n",
    "    done_mult = (1-dones)\n",
    "    doubleQ = Qvals[range(bs), argQmax]\n",
    "    targetQ = rewards + (gamma*doubleQ * done_mult)\n",
    "    _ = sess.run(mainDQN.update,feed_dict={mainDQN.input:states,mainDQN.targetQ:targetQ, mainDQN.action:actions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control parameter\n",
    "max_episode_len = 18000\n",
    "bs = 32\n",
    "target_network_update_freq = 10000\n",
    "gamma = 0.99\n",
    "exploration_initial = 1\n",
    "exploration_final = 0.1\n",
    "exploration_inference = 0.01\n",
    "exploration_decay_frames = 1000000\n",
    "replay_start_size = 5000\n",
    "max_frames = 50000000\n",
    "memory_size = 1000000 #1000000\n",
    "hidden = 512\n",
    "#interpol_factor = 0.001\n",
    "no_op_steps = 20\n",
    "gif_freq = 50\n",
    "learning_rate = 0.00001\n",
    "\n",
    "m = -(exploration_initial - exploration_final)/exploration_decay_frames\n",
    "b = exploration_initial - m*replay_start_size\n",
    "m2 = -(exploration_final - exploration_inference)/(max_frames - exploration_decay_frames - replay_start_size)\n",
    "b2 = exploration_final - m2*(replay_start_size + exploration_decay_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-07-17 01:33:50,795] From /home/fabiograetz/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "/home/fabiograetz/anaconda3/envs/deeplearning/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/fabiograetz/anaconda3/envs/deeplearning/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 201 2.0 200\n",
      "10 2018 1.4545454545454546 126\n",
      "20 4058 1.619047619047619 276\n",
      "30 5968 1.5806451612903225 268\n",
      "40 7748 1.4878048780487805 172\n",
      "50 9479 1.411764705882353 220\n",
      "60 11512 1.4918032786885247 199\n",
      "70 13109 1.3943661971830985 155\n",
      "80 14876 1.382716049382716 170\n",
      "90 16873 1.4285714285714286 225\n",
      "100 18572 1.4 152\n",
      "110 20550 1.45 269\n",
      "120 22236 1.38 188\n",
      "130 23971 1.36 248\n",
      "140 25969 1.42 187\n",
      "150 28050 1.5 126\n",
      "160 29972 1.48 297\n",
      "170 31568 1.48 168\n",
      "180 33235 1.46 121\n",
      "190 35406 1.5 173\n",
      "200 37029 1.47 245\n",
      "210 38787 1.41 122\n",
      "220 40402 1.39 124\n",
      "230 42260 1.41 203\n",
      "240 44339 1.44 167\n",
      "250 46167 1.38 268\n",
      "260 48030 1.36 182\n",
      "270 49632 1.37 156\n",
      "280 51257 1.35 199\n",
      "290 53376 1.34 168\n",
      "300 55120 1.37 151\n",
      "310 57011 1.41 125\n",
      "320 58777 1.45 172\n",
      "330 60713 1.47 151\n",
      "340 62441 1.37 273\n",
      "350 64316 1.4 152\n",
      "360 66590 1.5 264\n",
      "370 68295 1.54 126\n",
      "380 70211 1.62 170\n",
      "390 71969 1.54 199\n",
      "400 73839 1.57 233\n",
      "410 75837 1.6 197\n",
      "420 77401 1.55 173\n",
      "430 79630 1.63 199\n",
      "440 81365 1.65 229\n",
      "450 82907 1.56 184\n",
      "460 84547 1.41 128\n",
      "470 86585 1.48 245\n",
      "480 88621 1.51 229\n",
      "490 90482 1.52 258\n",
      "500 92791 1.62 123\n",
      "510 94569 1.56 178\n",
      "520 96372 1.62 155\n",
      "530 98322 1.55 228\n",
      "540 100198 1.59 152\n",
      "550 102351 1.73 198\n",
      "560 104376 1.83 206\n",
      "570 106440 1.82 405\n",
      "580 108349 1.78 170\n",
      "590 110387 1.82 128\n",
      "600 112174 1.71 169\n",
      "610 114003 1.72 248\n",
      "620 116081 1.79 196\n",
      "630 117994 1.77 155\n",
      "640 119989 1.78 171\n",
      "650 121896 1.73 155\n",
      "660 123416 1.6 125\n",
      "670 125234 1.56 202\n",
      "680 127063 1.53 168\n",
      "690 129035 1.54 197\n",
      "700 130974 1.57 249\n",
      "710 132864 1.6 184\n",
      "720 134504 1.49 127\n",
      "730 136358 1.47 123\n",
      "740 138205 1.44 249\n",
      "750 139985 1.43 199\n",
      "760 141723 1.47 171\n",
      "770 143352 1.42 209\n",
      "780 145336 1.49 199\n",
      "790 147042 1.43 123\n",
      "800 148876 1.4 172\n",
      "810 150649 1.36 127\n",
      "820 152450 1.4 248\n",
      "830 154410 1.44 205\n",
      "840 156534 1.49 198\n",
      "850 158906 1.63 259\n",
      "860 160762 1.67 126\n",
      "870 162618 1.72 201\n",
      "880 164249 1.61 276\n",
      "890 165988 1.6 197\n",
      "900 167794 1.6 299\n",
      "910 169435 1.57 181\n",
      "920 171594 1.66 150\n",
      "930 173506 1.65 121\n",
      "940 175590 1.66 124\n",
      "950 177438 1.51 257\n",
      "960 179307 1.52 260\n",
      "970 181258 1.54 249\n",
      "980 183296 1.64 270\n",
      "990 185031 1.65 121\n",
      "1000 186870 1.65 173\n",
      "1010 189088 1.78 193\n",
      "1020 191195 1.77 169\n",
      "1030 193107 1.79 267\n",
      "1040 194900 1.71 126\n",
      "1050 196931 1.78 177\n",
      "1060 199328 1.9 204\n",
      "1070 201364 1.92 207\n",
      "1080 203206 1.88 150\n",
      "1090 205177 1.93 297\n",
      "1100 207002 1.93 173\n",
      "1110 208736 1.81 123\n",
      "1120 210503 1.73 196\n",
      "1130 212415 1.71 243\n",
      "1140 214306 1.73 224\n",
      "1150 216316 1.71 244\n",
      "1160 218344 1.61 223\n",
      "1170 220588 1.66 294\n",
      "1180 222261 1.61 168\n",
      "1190 224258 1.62 199\n",
      "1200 225968 1.6 173\n",
      "1210 228007 1.69 178\n",
      "1220 230230 1.77 126\n",
      "1230 232200 1.78 199\n",
      "1240 234093 1.79 124\n",
      "1250 236045 1.76 349\n",
      "1260 238030 1.77 203\n",
      "1270 239920 1.7 182\n",
      "1280 241815 1.76 184\n",
      "1290 243610 1.72 198\n",
      "1300 245599 1.79 171\n",
      "1310 247383 1.7 216\n",
      "1320 249173 1.63 128\n",
      "1330 251063 1.62 205\n",
      "1340 253174 1.68 200\n",
      "1350 255145 1.69 126\n",
      "1360 257205 1.69 215\n",
      "1370 259001 1.66 229\n",
      "1380 260773 1.63 171\n",
      "1390 262902 1.68 267\n",
      "1400 264644 1.61 125\n",
      "1410 266408 1.61 122\n",
      "1420 268398 1.64 301\n",
      "1430 270436 1.67 178\n",
      "1440 272237 1.58 213\n",
      "1450 274027 1.53 167\n",
      "1460 276023 1.54 134\n",
      "1470 277956 1.57 217\n",
      "1480 279845 1.6 231\n",
      "1490 281791 1.57 153\n",
      "1500 283793 1.64 221\n",
      "1510 285627 1.66 173\n",
      "1520 287695 1.69 198\n",
      "1530 289669 1.65 180\n",
      "1540 291757 1.72 201\n",
      "1550 293586 1.74 168\n",
      "1560 295387 1.68 150\n",
      "1570 297074 1.62 172\n",
      "1580 298590 1.53 151\n",
      "1590 300486 1.51 130\n",
      "1600 302209 1.44 125\n",
      "1610 303787 1.39 126\n",
      "1620 305568 1.31 179\n",
      "1630 307362 1.27 198\n",
      "1640 309397 1.26 161\n",
      "1650 311621 1.35 174\n",
      "1660 313575 1.37 218\n",
      "1670 315450 1.42 126\n",
      "1680 317343 1.51 172\n",
      "1690 319179 1.52 186\n",
      "1700 321128 1.56 252\n",
      "1710 322998 1.62 200\n",
      "1720 324622 1.58 132\n",
      "1730 326754 1.67 184\n",
      "1740 328601 1.64 205\n",
      "1750 330275 1.51 207\n",
      "1760 332410 1.56 266\n",
      "1770 334454 1.59 220\n",
      "1780 336277 1.58 128\n",
      "1790 338392 1.63 251\n",
      "1800 339934 1.55 153\n",
      "1810 341809 1.55 152\n",
      "1820 343566 1.58 158\n",
      "1830 345626 1.59 202\n",
      "1840 347414 1.55 124\n",
      "1850 349143 1.55 253\n",
      "1860 350986 1.48 248\n",
      "1870 353075 1.49 316\n",
      "1880 355308 1.62 277\n",
      "1890 357083 1.54 180\n",
      "1900 359360 1.71 215\n",
      "1910 361209 1.72 208\n",
      "1920 363164 1.76 173\n",
      "1930 365236 1.75 163\n",
      "1940 367483 1.88 121\n",
      "1950 369527 2.0 214\n",
      "1960 371325 2.01 124\n",
      "1970 373175 1.96 128\n",
      "1980 375129 1.88 153\n",
      "1990 376997 1.89 201\n",
      "2000 379222 1.88 171\n",
      "2010 381331 1.92 366\n",
      "2020 383547 2.0 247\n",
      "2030 385383 1.96 155\n",
      "2040 387509 1.94 225\n",
      "2050 389333 1.86 121\n",
      "2060 391639 1.99 232\n",
      "2070 393853 2.08 231\n",
      "2080 395778 2.06 249\n",
      "2090 397787 2.11 127\n",
      "2100 399716 2.05 276\n",
      "2110 401404 1.96 127\n",
      "2120 403811 2.03 168\n",
      "2130 406114 2.15 367\n",
      "2140 408164 2.14 347\n",
      "2150 410036 2.16 205\n",
      "2160 411929 2.06 170\n",
      "2170 413834 1.99 290\n",
      "2180 416054 2.07 198\n",
      "2190 418302 2.13 275\n",
      "2200 420746 2.29 350\n",
      "2210 422998 2.45 186\n",
      "2220 425544 2.46 258\n",
      "2230 427742 2.43 316\n",
      "2240 429953 2.47 182\n",
      "2250 432292 2.6 122\n",
      "2260 434892 2.78 249\n",
      "2270 437375 2.95 315\n",
      "2280 439526 2.93 121\n",
      "2290 441299 2.83 181\n",
      "2300 443903 2.8 334\n",
      "2310 445816 2.7 239\n",
      "2320 448145 2.65 277\n",
      "2330 450277 2.65 208\n",
      "2340 452391 2.62 243\n",
      "2350 454660 2.59 230\n",
      "2360 456949 2.5 211\n",
      "2370 458863 2.32 159\n",
      "2380 461457 2.44 184\n",
      "2390 463947 2.65 244\n",
      "2400 466097 2.58 234\n",
      "2410 468551 2.71 166\n",
      "2420 471198 2.83 249\n",
      "2430 473810 2.93 229\n",
      "2440 476310 3.05 292\n",
      "2450 478612 3.07 152\n",
      "2460 480989 3.1 228\n",
      "2470 482828 3.11 126\n",
      "2480 484808 2.96 245\n",
      "2490 487017 2.88 260\n",
      "2500 489288 2.95 134\n",
      "2510 491430 2.94 161\n",
      "2520 493516 2.76 210\n",
      "2530 495953 2.72 258\n",
      "2540 498270 2.68 202\n",
      "2550 500741 2.75 211\n",
      "2560 502978 2.74 193\n",
      "2570 505540 2.94 214\n",
      "2580 508310 3.13 235\n",
      "2590 510803 3.23 247\n",
      "2600 513457 3.36 273\n",
      "2610 515927 3.41 122\n",
      "2620 518339 3.56 204\n",
      "2630 521132 3.71 199\n",
      "2640 523709 3.75 279\n",
      "2650 526285 3.79 196\n",
      "2660 528410 3.77 236\n",
      "2670 530909 3.74 264\n",
      "2680 533503 3.69 267\n",
      "2690 535668 3.58 200\n",
      "2700 537988 3.44 412\n",
      "2710 540154 3.36 198\n",
      "2720 542375 3.29 199\n",
      "2730 544498 3.08 181\n",
      "2740 546897 3.13 245\n",
      "2750 549342 3.16 216\n",
      "2760 551706 3.24 213\n",
      "2770 554225 3.32 229\n",
      "2780 556703 3.35 379\n",
      "2790 558939 3.42 217\n",
      "2800 561162 3.45 218\n",
      "2810 563715 3.59 216\n",
      "2820 565992 3.67 180\n",
      "2830 568700 3.85 213\n",
      "2840 571572 3.89 247\n",
      "2850 574206 3.99 276\n",
      "2860 576648 4.01 306\n",
      "2870 579295 4.07 308\n",
      "2880 581791 4.16 271\n",
      "2890 584150 4.21 301\n",
      "2900 586468 4.31 298\n",
      "2910 588958 4.34 219\n",
      "2920 591433 4.32 222\n",
      "2930 594077 4.39 250\n",
      "2940 596333 4.27 200\n",
      "2950 598891 4.26 253\n",
      "2960 601639 4.31 361\n",
      "2970 604081 4.28 209\n",
      "2980 606810 4.26 372\n",
      "2990 609291 4.31 205\n",
      "3000 611612 4.24 187\n",
      "3010 614304 4.26 128\n",
      "3020 616725 4.25 279\n",
      "3030 619459 4.14 198\n",
      "3040 621957 4.29 242\n",
      "3050 624289 4.2 215\n",
      "3060 626225 4.0 262\n",
      "3070 628643 3.99 228\n",
      "3080 631597 4.07 295\n",
      "3090 634473 4.21 294\n",
      "3100 637073 4.29 255\n",
      "3110 639874 4.33 250\n",
      "3120 642462 4.43 230\n",
      "3130 644938 4.48 449\n",
      "3140 647580 4.51 213\n",
      "3150 650266 4.52 232\n",
      "3160 653032 4.95 328\n",
      "3170 655693 4.98 214\n",
      "3180 658305 4.9 261\n",
      "3190 660686 4.75 261\n",
      "3200 663367 4.88 270\n",
      "3210 666516 5.05 310\n",
      "3220 668927 5.07 217\n",
      "3230 671754 5.16 454\n",
      "3240 674305 5.06 316\n",
      "3250 676790 5.06 180\n",
      "3260 679288 4.87 336\n",
      "3270 681463 4.76 247\n",
      "3280 683959 4.75 211\n",
      "3290 686821 4.95 259\n",
      "3300 689252 4.87 210\n",
      "3310 692096 4.69 229\n",
      "3320 694660 4.65 313\n",
      "3330 697322 4.52 243\n",
      "3340 699866 4.54 219\n",
      "3350 702499 4.58 348\n",
      "3360 705165 4.7 292\n",
      "3370 707498 4.73 182\n",
      "3380 709885 4.7 212\n",
      "3390 712627 4.6 344\n",
      "3400 715140 4.58 121\n",
      "3410 717829 4.56 214\n",
      "3420 720455 4.57 361\n",
      "3430 722988 4.63 228\n",
      "3440 725633 4.66 212\n",
      "3450 728341 4.68 294\n",
      "3460 730668 4.57 247\n",
      "3470 733266 4.75 211\n",
      "3480 735560 4.77 212\n",
      "3490 737947 4.75 254\n",
      "3500 740151 4.63 242\n",
      "3510 742683 4.67 252\n",
      "3520 745167 4.74 297\n",
      "3530 747886 4.73 246\n",
      "3540 750460 4.74 257\n",
      "3550 752812 4.63 211\n",
      "3560 755480 4.61 212\n",
      "3570 757853 4.45 209\n",
      "3580 760910 4.67 214\n",
      "3590 763298 4.71 252\n",
      "3600 765682 4.71 209\n",
      "3610 767982 4.54 244\n",
      "3620 770192 4.38 254\n",
      "3630 772627 4.35 213\n",
      "3640 775016 4.35 245\n",
      "3650 777492 4.33 211\n",
      "3660 779717 4.23 211\n",
      "3670 782464 4.32 294\n",
      "3680 784826 4.09 241\n",
      "3690 787308 4.02 259\n",
      "3700 789654 4.07 288\n",
      "3710 792183 4.36 245\n",
      "3720 794613 4.54 213\n",
      "3730 797008 4.53 213\n",
      "3740 799529 4.5 298\n",
      "3750 802030 4.52 211\n",
      "3760 804930 4.72 258\n",
      "3770 807459 4.71 323\n",
      "3780 810048 4.7 257\n",
      "3790 812246 4.56 180\n",
      "3800 814461 4.51 211\n",
      "3810 816825 4.3 245\n",
      "3820 819196 4.2 209\n",
      "3830 821600 4.21 212\n",
      "3840 823785 4.12 211\n",
      "3850 826245 4.21 209\n",
      "3860 828612 4.1 341\n",
      "3870 830935 4.11 211\n",
      "3880 833421 4.14 257\n",
      "3890 835901 4.22 289\n",
      "3900 838363 4.24 228\n",
      "3910 840722 4.28 211\n",
      "3920 843101 4.25 211\n",
      "3930 845461 4.23 249\n",
      "3940 847943 4.34 323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3950 850250 4.27 212\n",
      "3960 852440 4.14 211\n",
      "3970 854956 4.03 280\n",
      "3980 857838 4.22 211\n",
      "3990 860233 4.16 242\n",
      "4000 862769 4.22 211\n",
      "4010 865170 4.14 210\n",
      "4020 867895 4.31 211\n",
      "4030 870405 4.29 261\n",
      "4040 873202 4.31 295\n",
      "4050 876193 4.58 311\n",
      "4060 878706 4.69 260\n",
      "4070 881402 4.78 247\n",
      "4080 884108 4.64 327\n",
      "4090 887178 4.83 212\n",
      "4100 889636 4.8 211\n",
      "4110 892435 4.98 238\n",
      "4120 895007 4.81 255\n",
      "4130 897437 4.85 241\n",
      "4140 900196 4.85 240\n",
      "4150 902839 4.62 211\n",
      "4160 905279 4.56 261\n",
      "4170 908322 4.61 569\n",
      "4180 910791 4.49 227\n",
      "4190 913437 4.39 229\n",
      "4200 915959 4.41 211\n",
      "4210 918507 4.29 238\n",
      "4220 920797 4.22 248\n",
      "4230 923326 4.17 212\n",
      "4240 925962 4.15 339\n",
      "4250 928742 4.19 257\n",
      "4260 931466 4.29 295\n",
      "4270 933701 4.08 212\n",
      "4280 936198 4.08 248\n",
      "4290 938872 4.04 228\n",
      "4300 941374 4.01 455\n",
      "4310 943829 3.95 212\n",
      "4320 946445 4.07 377\n",
      "4330 948726 4.01 255\n",
      "4340 951249 3.98 211\n",
      "4350 953643 3.92 286\n",
      "4360 955850 3.81 212\n",
      "4370 958054 3.84 211\n",
      "4380 960304 3.79 260\n",
      "4390 963211 3.87 211\n",
      "4400 965811 3.95 308\n",
      "4410 968173 3.96 309\n",
      "4420 970464 3.88 212\n",
      "4430 972653 3.87 261\n",
      "4440 974994 3.8 287\n",
      "4450 978134 4.0 433\n",
      "4460 980785 4.08 261\n",
      "4470 983787 4.23 243\n",
      "4480 986630 4.42 211\n",
      "4490 989558 4.5 271\n",
      "4500 992583 4.6 407\n",
      "4510 995307 4.73 242\n",
      "4520 998004 4.95 211\n",
      "4530 1001549 5.44 456\n",
      "4540 1004951 5.77 393\n",
      "4550 1008199 5.84 345\n",
      "4560 1011341 6.21 261\n",
      "4570 1014402 6.41 278\n",
      "4580 1017852 6.66 229\n",
      "4590 1020992 6.84 289\n",
      "4600 1023951 7.04 373\n",
      "4610 1027085 7.35 335\n",
      "4620 1029998 7.35 302\n",
      "4630 1032937 7.12 274\n",
      "4640 1036111 7.0 535\n",
      "4650 1039396 6.95 281\n",
      "4660 1042704 6.84 402\n",
      "4670 1046023 6.73 291\n",
      "4680 1049771 6.77 403\n",
      "4690 1053255 6.69 463\n",
      "4700 1056623 6.56 310\n",
      "4710 1059992 6.41 258\n",
      "4720 1062999 6.43 336\n",
      "4730 1066632 6.64 307\n",
      "4740 1069791 6.74 278\n",
      "4750 1072976 6.72 211\n",
      "4760 1075838 6.58 260\n",
      "4770 1079093 6.65 341\n",
      "4780 1082375 6.46 419\n",
      "4790 1085839 6.46 338\n",
      "4800 1089486 6.57 240\n",
      "4810 1093218 6.62 503\n",
      "4820 1096599 6.67 287\n",
      "4830 1099695 6.43 372\n",
      "4840 1102744 6.29 211\n",
      "4850 1105974 6.31 308\n",
      "4860 1109525 6.55 486\n",
      "4870 1112690 6.54 241\n",
      "4880 1115585 6.46 288\n",
      "4890 1118852 6.41 373\n",
      "4900 1122587 6.49 242\n",
      "4910 1126088 6.5 481\n",
      "4920 1129181 6.49 328\n",
      "4930 1133196 6.8 403\n",
      "4940 1136507 6.88 345\n",
      "4950 1140080 6.99 407\n",
      "4960 1143772 6.91 260\n",
      "4970 1147424 6.89 358\n",
      "4980 1150787 7.02 322\n",
      "4990 1154812 7.31 406\n",
      "5000 1158880 7.29 524\n",
      "5010 1163002 7.51 603\n",
      "5020 1166478 7.53 322\n",
      "5030 1170187 7.46 324\n",
      "5040 1174558 7.74 549\n",
      "5050 1178936 7.99 444\n",
      "5060 1183317 8.26 410\n",
      "5070 1187486 8.62 441\n",
      "5080 1191346 8.82 385\n",
      "5090 1195913 9.19 431\n",
      "5100 1200741 9.63 602\n",
      "5110 1205370 9.82 411\n",
      "5120 1209906 10.38 391\n",
      "5130 1214498 10.67 536\n",
      "5140 1219338 11.0 411\n",
      "5150 1224228 11.19 481\n",
      "5160 1229267 11.48 679\n",
      "5170 1234272 11.79 509\n",
      "5180 1239319 12.19 344\n",
      "5190 1244517 12.22 528\n",
      "5200 1249929 12.45 488\n",
      "5210 1255080 12.63 730\n",
      "5220 1259831 12.56 372\n",
      "5230 1265047 12.84 415\n",
      "5240 1269985 12.88 478\n",
      "5250 1274575 12.75 465\n",
      "5260 1279407 12.58 506\n",
      "5270 1284087 12.51 426\n",
      "5280 1288747 12.43 433\n",
      "5290 1293013 12.12 410\n",
      "5300 1297993 12.03 488\n",
      "5310 1302529 11.82 380\n",
      "5320 1307282 11.82 493\n",
      "5330 1312180 11.66 366\n",
      "5340 1317076 11.66 363\n",
      "5350 1321746 11.69 471\n",
      "5360 1326825 11.86 344\n",
      "5370 1331579 11.79 403\n",
      "5380 1335939 11.53 511\n",
      "5390 1340512 11.49 551\n",
      "5400 1345127 11.19 603\n",
      "5410 1350343 11.29 355\n",
      "5420 1355213 11.28 478\n",
      "5430 1360430 11.36 657\n",
      "5440 1365019 11.28 389\n",
      "5450 1369949 11.38 365\n",
      "5460 1374230 11.2 389\n",
      "5470 1379278 11.22 453\n",
      "5480 1384601 11.61 523\n",
      "5490 1389266 11.8 553\n",
      "5500 1393059 11.62 392\n",
      "5510 1397799 11.41 617\n",
      "5520 1402396 11.3 544\n",
      "5530 1406167 10.82 453\n",
      "5540 1410290 10.69 447\n",
      "5550 1415096 10.73 478\n",
      "5560 1419506 10.59 420\n",
      "5570 1423820 10.46 348\n",
      "5580 1428612 10.4 449\n",
      "5590 1433539 10.47 453\n",
      "5600 1437988 10.62 416\n",
      "5610 1442702 10.83 386\n",
      "5620 1446884 10.73 314\n",
      "5630 1451341 10.89 513\n",
      "5640 1455681 10.75 447\n",
      "5650 1460223 10.54 474\n",
      "5660 1465200 10.82 459\n",
      "5670 1469644 10.78 403\n",
      "5680 1474788 10.8 527\n",
      "5690 1479202 10.49 452\n",
      "5700 1483771 10.48 555\n",
      "5710 1488982 10.58 452\n",
      "5720 1493706 10.91 366\n",
      "5730 1497781 10.84 341\n",
      "5740 1502748 11.25 675\n",
      "5750 1507183 11.12 420\n",
      "5760 1512028 11.09 534\n",
      "5770 1517561 11.29 571\n",
      "5780 1522478 11.12 403\n",
      "5790 1527325 11.26 558\n",
      "5800 1532544 11.42 492\n",
      "5810 1537594 11.18 486\n",
      "5820 1542692 11.07 522\n",
      "5830 1548240 11.49 485\n",
      "5840 1553689 11.48 492\n",
      "5850 1559417 12.01 415\n",
      "5860 1564467 11.93 450\n",
      "5870 1569863 11.94 565\n",
      "5880 1574954 12.08 445\n",
      "5890 1580341 12.28 602\n",
      "5900 1585866 12.31 521\n",
      "5910 1591524 12.84 433\n",
      "5920 1597231 13.02 708\n",
      "5930 1602958 13.16 568\n",
      "5940 1608413 13.16 514\n",
      "5950 1613857 12.94 619\n",
      "5960 1619075 13.04 612\n",
      "5970 1624318 13.04 410\n",
      "5980 1630628 13.26 681\n",
      "5990 1636136 13.27 593\n",
      "6000 1642087 13.5 490\n",
      "6010 1647708 13.29 403\n",
      "6020 1653488 13.3 682\n",
      "6030 1659781 13.46 700\n",
      "6040 1665221 13.62 562\n",
      "6050 1671259 13.88 566\n",
      "6060 1677514 14.11 659\n",
      "6070 1683492 14.38 656\n",
      "6080 1689630 14.45 808\n",
      "6090 1696118 14.89 583\n",
      "6100 1701690 14.72 719\n",
      "6110 1708226 15.04 558\n",
      "6120 1714896 15.41 614\n",
      "6130 1720594 15.17 607\n",
      "6140 1727033 15.2 628\n",
      "6150 1734386 15.92 781\n",
      "6160 1741070 16.16 700\n",
      "6170 1748042 16.68 755\n",
      "6180 1753966 16.58 480\n",
      "6190 1760429 16.58 705\n",
      "6200 1766749 17.02 649\n",
      "6210 1773378 17.08 715\n",
      "6220 1779866 17.06 693\n",
      "6230 1786872 17.49 713\n",
      "6240 1793232 17.7 723\n",
      "6250 1799213 16.87 797\n",
      "6260 1806268 17.2 681\n",
      "6270 1812731 16.84 689\n",
      "6280 1819396 17.19 526\n",
      "6290 1825488 17.12 427\n",
      "6300 1832002 17.12 708\n",
      "6310 1838591 16.95 765\n",
      "6320 1844965 16.84 740\n",
      "6330 1851603 16.84 708\n",
      "6340 1858251 16.97 698\n",
      "6350 1864998 17.32 692\n",
      "6360 1871160 16.97 570\n",
      "6370 1877449 16.92 819\n",
      "6380 1884531 17.1 649\n",
      "6390 1891239 17.36 805\n",
      "6400 1898849 17.87 830\n",
      "6410 1906090 18.2 747\n",
      "6420 1912562 18.34 746\n",
      "6430 1919290 18.44 636\n",
      "6440 1925718 18.26 659\n",
      "6450 1933261 18.6 817\n",
      "6460 1940567 18.92 847\n",
      "6470 1947414 19.25 605\n",
      "6480 1954536 19.26 795\n",
      "6490 1961484 19.18 718\n",
      "6500 1968914 18.88 722\n",
      "6510 1975779 18.78 884\n",
      "6520 1982668 18.91 640\n",
      "6530 1989900 18.94 717\n",
      "6540 1997629 19.42 527\n",
      "6550 2004480 19.15 536\n",
      "6560 2011387 19.0 779\n",
      "6570 2019198 19.5 819\n",
      "6580 2026653 19.73 722\n",
      "6590 2033847 20.02 797\n",
      "6600 2042021 20.61 797\n",
      "6610 2050146 21.18 617\n",
      "6620 2058078 21.56 663\n",
      "6630 2065840 21.76 820\n",
      "6640 2073106 21.57 628\n",
      "6650 2080036 21.81 650\n",
      "6660 2088019 22.3 719\n",
      "6670 2095248 21.86 898\n",
      "6680 2102568 21.78 889\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a954ef87c803>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_episode_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mnewframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m#########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mauxiliary\u001b[0m \u001b[0mdiagnostic\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhelpful\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdebugging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msometimes\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \"\"\"\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mauxiliary\u001b[0m \u001b[0mdiagnostic\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhelpful\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdebugging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msometimes\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \"\"\"\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/gym/envs/atari/atari_env.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/atari_py/ale_python_interface.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0male_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgame_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "myMemoryBuffer = MemoryBuffer(size=memory_size, batch_size=bs)\n",
    "mainDQN = dqn(hidden, learning_rate)\n",
    "targetDQN = dqn(hidden)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "restore = False\n",
    "\n",
    "\n",
    "variables = tf.trainable_variables()\n",
    "mainDQN_vars = variables[0:len(variables)//2]\n",
    "targetDQN_vars = variables[len(variables)//2:]\n",
    "updateTargetVars = updateTargetVars_full(mainDQN_vars, targetDQN_vars)\n",
    "frameprocessor = processFrame()\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if restore == True:\n",
    "        saver.restore(sess,tf.train.latest_checkpoint(PATH))\n",
    "\n",
    "    frame_number = 0\n",
    "    episode_number=0\n",
    "    rewards = []\n",
    "    while frame_number < max_frames:\n",
    "        if episode_number % gif_freq == 0: \n",
    "            frames_for_gif = []\n",
    "        frame = env.reset()\n",
    "        done = False\n",
    "        done2 = False\n",
    "        last_lives = 0\n",
    "        for _ in range(random.randint(1, no_op_steps)):\n",
    "            frame, _, _, _ = env.step(0)\n",
    "        processed_frame = frameprocessor.process(sess,frame)\n",
    "        state = np.repeat(processed_frame,4, axis=2)\n",
    "        ep_reward_sum = 0\n",
    "        for j in range(max_episode_len):\n",
    "            action = getaction(frame_number,state)\n",
    "            newframe, reward, done, info = env.step(action)\n",
    "            \n",
    "            #########\n",
    "            \n",
    "            if info['ale.lives'] < last_lives:\n",
    "                done2 = True;\n",
    "            else:\n",
    "                done2 = done\n",
    "                \n",
    "            \n",
    "\n",
    "            last_lives = info['ale.lives']\n",
    "            \n",
    "            #########\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            if episode_number % gif_freq == 0: \n",
    "                frames_for_gif.append(newframe)\n",
    "                        \n",
    "            processed_newframe = frameprocessor.process(sess,newframe)\n",
    "            newstate = np.append(state[:,:,1:],processed_newframe,axis=2)\n",
    "\n",
    "            frame_number += 1\n",
    "            \n",
    "            myMemoryBuffer.addExperience(action=action, frame=processed_newframe[:,:,0], reward=reward, done=done2)\n",
    "            \n",
    "            if frame_number > replay_start_size:\n",
    "                learn()\n",
    "            \n",
    "            \n",
    "            if frame_number % target_network_update_freq == 0 and frame_number > replay_start_size:\n",
    "                update_ops = updateTargetVars\n",
    "                for op in update_ops:\n",
    "                    sess.run(op)\n",
    "            \n",
    "            \n",
    "            ep_reward_sum += reward\n",
    "            state = newstate\n",
    "            if done == True:\n",
    "                break\n",
    "        rewards.append(ep_reward_sum)\n",
    "        if episode_number % gif_freq == 0: \n",
    "            generate_gif(sess, frame_number, frames_for_gif)\n",
    "        if episode_number % 50 == 0:\n",
    "            saver.save(sess,PATH+'/my_model',global_step=frame_number)\n",
    "        if episode_number % 10 == 0:\n",
    "            print(episode_number, frame_number,np.mean(rewards[-100:]), j)\n",
    "            with open('rewards.dat','a') as f:\n",
    "                print(episode_number, frame_number,np.mean(rewards[-100:]), j,file=f)\n",
    "        episode_number += 1\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(elapsed/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "init = tf.global_variables_initializer()\n",
    "frameprocessor = processFrame()\n",
    "mainDQN = dqn(hidden, learning_rate)\n",
    "targetDQN = dqn(hidden)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver.restore(sess,tf.train.latest_checkpoint(PATH))\n",
    "    frames_for_gif = []\n",
    "    done = False\n",
    "    frame = env.reset()\n",
    "    processed_frame = frameprocessor.process(sess,frame)\n",
    "    state = np.repeat(processed_frame,4, axis=2)\n",
    "    ep_reward_sum = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = getaction(1,state,inference=True)\n",
    "        newframe, reward, done, _ = env.step(action)\n",
    "            \n",
    "        frames_for_gif.append(newframe)\n",
    "                        \n",
    "        processed_newframe = frameprocessor.process(sess,newframe)\n",
    "        newstate = np.append(state[:,:,1:],processed_newframe,axis=2)\n",
    "\n",
    "\n",
    "        ep_reward_sum += reward\n",
    "        state = newstate\n",
    "    print(\"Total reward: %s\" % ep_reward_sum)\n",
    "    generate_gif(sess,0, frames_for_gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning]",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
